# RESUME-CLASSIFICATION-

🗂📑📝🖥The document classification solution should significantly reduce the manual human effort in the HRM.
         It should achieve a higher level of accuracy and automation with minimal human intervention.

📌📄🧠🖥A resume is a brief summary of your skills and experience. Companies recruiters and HR teams have a tough time scanning thousands of qualified resumes. 
         Spending too many labor hours segregating candidates 
         resume's manually is a waste of a company's time, money, and productivity. Recruiters, therefore, use resume classification in order to streamline the resume and applicant screening process. NLP technology 
         allows recruiters to electronically gather, store, and organize large quantities of resumes. Once acquired, the resume data can be easily searched through and analyzed.

🔸The basic data analysis process performed such as data collection, text mining, data cleaning, exploratory data analysis, data visualization.

🔹Building a Machine learning model for Resume Classification using Python and basic Natural language processing techniques.

🔸Used Python's libraries to implement various NLP techniques like tokenization, lemmatization, parts of speech tagging, etc.

🔹A resume classification analyzes resume data and extracts the information into the machine-readable output. It helps automatically store, organize, and analyze the resume data to find out the candidate for the 
  particular job position and requirements.
     
🔸The aim of this project is achieved by performing the various data analysis methods and using the Machine Learning models and Natural Language Processing which will help in classifying the categories of the 
   resume and building the Resume Classification Model.

📌💻🧠In this work, I compare different types of machine-learning algorithms:

        🎯K-Nearest Neighbors
        🌲Decision Tree
        🌲Random Forest
       🚀Support Vector Machine
          Logistic Regression
 📂 Resumes_Docx
- Contains multiple **subfolders**, each with various **resume files** (`.docx`, `.doc`, `.pdf`).
- **Note:**  
  - The **first subfolder** contains a **duplicate file** only → **Removed** for cleanliness.

---

## 🛠️ convert_files_to_txt.py
- **Purpose:** Converts all resume files to **`.txt`** format.
- **Naming Convention:**  
  - Output filename = **`subfolder_name + original_filename + .txt`**.

---

## 📂 Processed_Resumes_Txt
- Stores all **converted `.txt` resumes** generated by `convert_files_to_txt.py`.

---

## 🛠️ making_csv.py
- **Purpose:** Combines all `.txt` files into a **single CSV** file.
- **CSV Structure:**  
  - **Column 1:** Filename  
  - **Column 2:** Text data extracted from each file.

---

## 📄 resumes_from_txt.csv
- The **output CSV** generated from text files.
- **Shape:** `(79, 2)`  
  *(79 resumes, 2 columns: filename and text)*

---

## 📓 resumes.ipynb
- **Objective:**  
  - Clean the CSV further by **assigning a Role** to each resume based on filename patterns.
  - Final format: **`Role`** and **`Data`** columns.

---

## 📈 eda.ipynb
- **Exploratory Data Analysis (EDA)** on the cleaned resume dataset.
- Focus areas:
  - Role distributions
  - Text lengths
  - Word clouds and more.

---

## 🧠 model.ipynb
- **Model building notebook** for:
  - Resume text classification
  - Role prediction
- Includes preprocessing, vectorization, model training, and evaluation.
